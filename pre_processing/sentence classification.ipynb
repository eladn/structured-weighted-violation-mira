{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import os\n",
    "import numpy as np\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('data/sentences/rt-polarity-utf8.neg') as f:\n",
    "    neg = f.read().splitlines()\n",
    "with open('data/sentences/rt-polarity-utf8.pos') as f:\n",
    "    pos = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5349, 5346)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(neg), len(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pos + neg\n",
    "target = [1 for _ in range(len(pos))] + [-1 for _ in range(len(neg))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neg_train_size = int(len(neg) * 0.8)\n",
    "pos_train_size = int(len(pos) * 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neg_train, neg_test = neg[:neg_train_size], neg[neg_train_size:]\n",
    "pos_train, pos_test = pos[:pos_train_size], pos[pos_train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = neg_train + pos_train\n",
    "test_data = neg_test + pos_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data) + len(test_data) == len(neg) + len(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neg_target_train = [-1 for i in range(len(neg_train))]\n",
    "neg_target_test = [-1 for i in range(len(neg_test))]\n",
    "pos_target_train = [1 for i in range(len(pos_train))]\n",
    "pos_target_test = [1 for i in range(len(pos_test))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_train = neg_target_train + pos_target_train\n",
    "target_test = neg_target_test + pos_target_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ofir/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.73598130841121501"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf_svm = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
    "                         ('clf-svm', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, n_iter=5, random_state=42))])\n",
    "\n",
    "text_clf_svm = text_clf_svm.fit(train_data, target_train)\n",
    "predicted_svm = text_clf_svm.predict(test_data)\n",
    "np.mean(predicted_svm == target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ofir/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Training Support Vector Machines - SVM and calculating its performance\n",
    "text_clf_svm = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
    "                         ('clf-svm', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, n_iter=5, random_state=42))])\n",
    "\n",
    "text_clf_svm = text_clf_svm.fit(data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_documents_path = \"data/documents/pos\"\n",
    "neg_documents_path = \"data/documents/neg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_documents = []\n",
    "neg_documents = []\n",
    "\n",
    "for file_name in os.listdir(pos_documents_path):\n",
    "    with open(os.path.join(pos_documents_path, file_name)) as f:\n",
    "        pos_documents.append(f.read().splitlines())\n",
    "        \n",
    "for file_name in os.listdir(neg_documents_path):\n",
    "    with open(os.path.join(neg_documents_path, file_name)) as f:\n",
    "        neg_documents.append(f.read().splitlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1000)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pos_documents), len(neg_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_pos_to_sentence(sentence):\n",
    "    response = requests.post(\"http://text-processing.com/api/tag/\", data={\"text\": sentence, \"output\": \"iob\"})\n",
    "    if response.status_code != 200:\n",
    "        return None\n",
    "    response_list = response.json().get(\"text\").split(\"\\n\")\n",
    "    return \" \".join([\"_\".join(var.split(\" \")[0:2]) for var in response_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_and_add_pos_documents(documents):\n",
    "    output = []\n",
    "    for i, doc in enumerate(documents):\n",
    "        results = text_clf_svm.predict(doc)\n",
    "        for sentence, label in zip(doc, results):\n",
    "            posed_sentence = add_pos_to_sentence(sentence)\n",
    "            if posed_sentence is None:\n",
    "                print(\"Document: {}\".formate(i))\n",
    "                return output\n",
    "            output.append(\"{}\\t{}\".format(label, posed_sentence))\n",
    "        output.append(\"\")\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_output = predict_and_add_pos_documents(pos_documents)\n",
    "neg_output = predict_and_add_pos_documents(neg_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thefile = open('../data/pos.txt', 'w')\n",
    "for sentence in pos_output:\n",
    "    thefile.write(\"%s\\n\" % sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thefile = open('../data/neg.txt', 'w')\n",
    "for sentence in neg_output:\n",
    "    thefile.write(\"%s\\n\" % sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
